---
title: "Movielens Machine Learning Project Report"
author: "Lorenzo Luna"
date: "06/12/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, echo=FALSE, include=FALSE}
################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

library(caret)
library(tidyverse)
```

## Intro

We will be implementing a recommendation system following the approach explained in this course.

The movielens dataset is made up of 10 million observations, each corresponding to a rating given to a movie by an user. Each observation has 6 variables:

```{r edx}
head(edx)
```

The variables userId and movieId are numeric identifiers for users and movies respectively. The rating variable is the numeric rating given by the indicated user to the indicated movie, in a scale from 0.5 to 5 by increments of 0.5 (due to half star ratings). The variables title and genre are characters and indicate the title of the movie (which may not be unique, therefore it is important to distinguish movies by movieId) and the genres associated with it. The timestamp date variable indicates when the rating was expressed.

Predicting a user's rating of a movie is a regression machine learning problem because we are predicting a numerical value. We will use a linear model that predicts ratings accounting for the biases of specific movies and users, caused by movies being either good or bad, and users having higher or lower quality standards.

To increase the precision of our model, we will regularize these biases to penalize users and movies for which we have too little data to make a well-informed prediction, tuning the $\lambda$ parameter with cross-validation.

## Method

The data shows that there is a bias effect caused by both the users and the movies, thus we will be estimating this effect for each user and movie, in order to predict ratings expressed by those users on movies they previously didn't rate.

```{r biases}
edx %>%
  group_by(movieId) %>%
  summarize(movie_bias = mean(rating)) %>%
  ggplot(aes(movie_bias)) +
  geom_histogram(bins = 70) + 
  geom_vline(aes(xintercept = mean(movie_bias), color = "mean"),
             linetype = "dashed", size = .5, show.legend = TRUE) +
  scale_color_manual(name = "", values = c("blue")) +
  ggtitle("Movie Bias Distribution")

edx %>%
  group_by(userId) %>%
  summarize(user_bias = mean(rating)) %>%
  ggplot(aes(user_bias)) +
  geom_histogram(bins = 50) +
  geom_vline(aes(xintercept = mean(user_bias), color = "mean"),
             linetype = "dashed", size = .5, show.legend = TRUE) +
  scale_color_manual(name = "", values = c("blue")) +
  ggtitle("User Bias Distribution")
```

As previously shown during the course, the number of movies that have only received few ratings is very high with half the movies having received less than about 125 ratings. Because of this regularization might help with improving the accuracy of the model. We also see that similarly, most users have expressed less than about 65 ratings, with a steadily decreasing amount of users being more prolific in expressing ratings. Regularization can be helpful here too.


```{r histratings, echo = TRUE}
edx %>%
  group_by(movieId) %>%
  summarize(ratings_by_movie = n()) %>%
  ggplot(aes(x = ratings_by_movie, y = ..count..)) +
  geom_histogram(bins = 30) +
  geom_vline(aes(xintercept = median(ratings_by_movie), color = "median"),
             linetype = "dashed", size = .5, show.legend = TRUE) +
  scale_x_log10() +
  scale_color_manual(name = "", values = c("red")) +
  ggtitle("Movie Ratings Distribution")

edx %>%
  group_by(userId) %>%
  summarize(ratings_by_user = n()) %>%
  ggplot(aes(x = ratings_by_user, y = ..count..)) +
  geom_histogram(bins = 30) +
  geom_vline(aes(xintercept = median(ratings_by_user), color = "median"),
             linetype = "dashed", size = .5, show.legend = TRUE) +
  scale_x_log10() +
  scale_color_manual(name = "", values = c("red")) +
  ggtitle("User Ratings Distribution")
```

Given these observation, we will train a simple machine learning algorithm that estimates regularized biases for each user and movie and uses those, as well as the overall mean of ratings, to make a prediction on unknown ratings, through the following model: $$Y_{u,i} = \mu + b_{i} + b_{u} + \varepsilon_{u,i}$$
Where $Y_{u,i}$ is the rating from user $u$ of movie $i$, $\varepsilon_{u,i}$ is an indipendent and identically distributed random variable representing the error in our estimate, $\mu$ is the mean of all ratings, $b_{i}$ is the regularized bias effect for movie $i$ and $b_{u}$ is the regularized bias effect for user $u$. These biases are regularized using the optimal parameter $\lambda$ determined using cross-validation on the test set. They are estimated as follows: $$\hat{b}_{i}(\lambda) = \frac{1}{\lambda + n_{i}}\sum^{n_{i}}_{u = 1}(Y_{u,i} - \hat{\mu})$$ $$\hat{b}_{u}(\lambda) = \frac{1}{\lambda + n_{u}}\sum^{n_{u}}_{i = 1}(Y_{u,i} - \hat{b}_{i}(\lambda) - \hat{\mu})$$

The goal is to minimize the root mean squared error (RMSE) of our prediction, defined as such: $$RMSE = \sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{u,i} - y_{u,i})^2}$$
Where $\hat{y}_{u,i}$ is our prediction of the true value $y_{u,i}$.

## Results

After running the provided initial setup code we split the edx dataset into a training and a test set, in order to avoid using the validation dataset as a test set

```{r partition}

#create training and test sets from edx

train_ind = createDataPartition(edx$rating, p = 0.9, list = FALSE)
train_edx = edx[train_ind,]
test_edx = edx[-train_ind,]

#remove from test set users and movies not present in training set

test_edx <- test_edx %>% 
  semi_join(train_edx, by = "movieId") %>%
  semi_join(train_edx, by = "userId")
```

We define the RMSE function, that calculates the root mean squared error of our estimate. We will use this function to evaluate the accuracy of our prediction.

```{r RMSE}
#define RMSE output function for solution evaluation

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

We now want to optimize the tuning parameter $\lambda$ by using cross-validation on the test set we've created.

```{r lambdas}
#optimize tuning parameter lambda validating on the test set

lambda_RMSE = function(lambda) {
#calculate overall rating mean
mu <- mean(train_edx$rating)

#calculate regularized movie bias for each movie using lambda
b_i <- train_edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

#calculate regularized user bias using lambda
b_u <- train_edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

#predict ratings on the test set
predicted_ratings <- 
  test_edx %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

return(RMSE(test_edx$rating, predicted_ratings))

}
#try lambdas from 1 to 10 by increments of 0.25
lambdas = seq(1,10,0.25)
rmses = sapply(lambdas, lambda_RMSE)

#pick best lambda
lambda = lambdas[which.min(rmses)]

#show lambda and qplot
qplot(lambdas, rmses)
lambda
```
As shown in the plot the optimal value of $\lambda$ seems to be somewhere within a 0.25-neighborhood of the displayed value. We can further improve the precision of our optimization by testing a greater amount of values but within the neighborhood of the value.

```{r precision}
#try lambdas in the neighborhood of the previous optimum by increments of 0.005
lambdas = seq(lambda-0.25,lambda+0.25, 0.005)
rmses = sapply(lambdas, lambda_RMSE)

#pick best lambda
lambda = lambdas[which.min(rmses)]

#show lambda and qplot
qplot(lambdas, rmses)
lambda
```

As shown by the console output the optimal value of $\lambda$ has improved in precision compared to the earlier estimate.

We can now run the model on the validation set using the optimal estimate of the parameter $\lambda$ and calculate the RMSE to evaluate its precision.

```{r final}
#calculate overall rating mean
mu <- mean(edx$rating)

#calculate regularized movie bias with optimized lambda
b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

#calculate regularized user bias with optimized lambda
b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

#predict ratings on the validation set
predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

#display resulting RMSE
RMSE(validation$rating, predicted_ratings)
```

We achieve an RMSE value lower than 0.8649.

## Conclusion

We have defined a model for predicting a user's rating of a previously unrated movie based on the estimated user and movie biases. This captures the fact that users tend to have different (biased) quality standards when rating movies and the fact that movies tend to be rated depending on their quality, which corresponds to a deviation from the mean (a bias) in their ratings.

Regularizing the user and movie biases improves the accuracy of the model as the relevance of data with small sample sizes is reduced, since we have seen that this happens often in this dataset.

The model's accuracy is acceptable considering its computational simplicity which results in minimal run-time. This model is limited because it ignores the genre and timestamp variables, and doesn't model patterns in the data like users only liking a particular set of genres, or users liking a movie more if they liked movies in the same trilogy or series.

Such patterns would be better recognized by a machine learning algorithm utilizing clustering or matrix factorization on this dataset. This would likely require some form of dimensionality reduction to render the problem tractable, like Principal Component Analysis (PCA).